{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "labels = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('./data/training'):\n",
    "    for filename in filenames:\n",
    "        if dirname == './data/training\\\\Fried food':\n",
    "            X_list.append(\n",
    "                cv.cvtColor(\n",
    "                    cv.imread(os.path.join(dirname, filename))\n",
    "                    ,cv.COLOR_BGR2RGB)\n",
    "            )\n",
    "            labels.append('FriedFood')\n",
    "        elif dirname == './data/training\\\\Meat':\n",
    "            X_list.append(cv.cvtColor(\n",
    "                    cv.imread(os.path.join(dirname, filename))\n",
    "                    ,cv.COLOR_BGR2RGB)\n",
    "            )\n",
    "            labels.append('Meat')\n",
    "\n",
    "X = np.asarray(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        meanR      varR     skewR     meanG      varG     skewG     meanB  \\\n",
      "0    0.476121  0.158375 -0.136288  0.153131  0.083122  0.052147  0.051228   \n",
      "1    0.744509  0.134182 -0.136444  0.421190  0.160822 -0.032004  0.124460   \n",
      "2    0.598654  0.180841  0.075462  0.349525  0.187097  0.149022  0.180766   \n",
      "3    0.543399  0.243265  0.185622  0.355875  0.256737  0.259721  0.224853   \n",
      "4    0.431776  0.288479  0.094911  0.240741  0.195905  0.147508  0.120904   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "995  0.311795  0.317605  0.307726  0.379208  0.320332  0.288455  0.263959   \n",
      "996  0.557956  0.169024 -0.155681  0.207986  0.089012  0.092137  0.031138   \n",
      "997  0.730964  0.193817 -0.162832  0.460730  0.259972 -0.157646  0.346239   \n",
      "998  0.502568  0.256428  0.217433  0.377095  0.294429  0.295665  0.211720   \n",
      "999  0.496319  0.276482 -0.151642  0.316047  0.213813  0.136375  0.139559   \n",
      "\n",
      "         varB     skewB  \n",
      "0    0.039956  0.043234  \n",
      "1    0.139556  0.165922  \n",
      "2    0.139971  0.126389  \n",
      "3    0.223336  0.256319  \n",
      "4    0.105074  0.107921  \n",
      "..        ...       ...  \n",
      "995  0.310424  0.310169  \n",
      "996  0.031603  0.041141  \n",
      "997  0.218637 -0.116527  \n",
      "998  0.252140  0.272785  \n",
      "999  0.137142  0.154666  \n",
      "\n",
      "[1000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import ColorMoments as cm\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "meanR_list = []\n",
    "varR_list = []\n",
    "skewR_list = []\n",
    "meanG_list = []\n",
    "varG_list = []\n",
    "skewG_list = []\n",
    "meanB_list = []\n",
    "varB_list = []\n",
    "skewB_list = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    h = X[i].shape[0]\n",
    "    w = X[i].shape[1]\n",
    "    ymin, ymax, xmin, xmax = h//3, h*2//3, w//3, w*2//3\n",
    "    crop = X[i][ymin:ymax, xmin:xmax]\n",
    "    resized = cv.resize(crop, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    meanR, varR, skewR = cm.getColorMoment(crop[:,:,0]/255)\n",
    "    meanG, varG, skewG = cm.getColorMoment(crop[:,:,1]/255)\n",
    "    meanB, varB, skewB = cm.getColorMoment(crop[:,:,2]/255)\n",
    "    \n",
    "    meanR_list.append(meanR)\n",
    "    varR_list.append(varR)\n",
    "    skewR_list.append(skewR)\n",
    "    meanG_list.append(meanG)\n",
    "    varG_list.append(varG)\n",
    "    skewG_list.append(skewG)\n",
    "    meanB_list.append(meanB)\n",
    "    varB_list.append(varB)\n",
    "    skewB_list.append(skewB)\n",
    "\n",
    "df['meanR'] = meanR_list\n",
    "df['varR'] = varR_list\n",
    "df['skewR'] = skewR_list\n",
    "df['meanG'] = meanG_list\n",
    "df['varG'] = varG_list\n",
    "df['skewG'] = skewG_list\n",
    "df['meanB'] = meanB_list\n",
    "df['varB'] = varB_list\n",
    "df['skewB'] = skewB_list\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import greycomatrix, greycoprops\n",
    "def calc_glcm_all_agls(img, props, dists=[5], agls=[0, np.pi/4, np.pi/2, 3*np.pi/4], lvl=256, sym=True, norm=True):\n",
    "    \n",
    "    glcm = greycomatrix(img, \n",
    "                        distances=dists, \n",
    "                        angles=agls, \n",
    "                        levels=lvl,\n",
    "                        symmetric=sym, \n",
    "                        normed=norm)\n",
    "    feature = []\n",
    "    glcm_props = [propery for name in props for propery in greycoprops(glcm, name)[0]]\n",
    "    for item in glcm_props:\n",
    "            feature.append(item)\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glcm_channel(X,channel):\n",
    "    ch = 0\n",
    "    if channel == 'R':\n",
    "        ch = 0\n",
    "    elif channel == 'G':\n",
    "        ch = 1\n",
    "    elif channel == 'B':\n",
    "        ch = 2\n",
    "            \n",
    "    gray_list = []\n",
    "    for i in range(len(X)):\n",
    "        gray = X[i][:,:,ch]\n",
    "\n",
    "        h = gray.shape[0]\n",
    "        w = gray.shape[1]\n",
    "        ymin, ymax, xmin, xmax = h//3, h*2//3, w//3, w*2//3\n",
    "        crop = gray[ymin:ymax, xmin:xmax]\n",
    "\n",
    "        resized = cv.resize(crop, (0,0), fx=0.5, fy=0.5)\n",
    "        gray_list.append(crop)\n",
    "\n",
    "    properties = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']\n",
    "\n",
    "    glcm_all_agls = []\n",
    "    for img, label in zip(gray_list, labels): \n",
    "        glcm_all_agls.append(\n",
    "                calc_glcm_all_agls(img, \n",
    "                                    props=properties)\n",
    "                                )\n",
    "\n",
    "    columns = []\n",
    "    angles = ['0', '45', '90','135']\n",
    "    for name in properties :\n",
    "        for ang in angles:\n",
    "            columns.append(name + \"_\" + ang +\"_\"+ channel)\n",
    "    return pd.DataFrame(glcm_all_agls, columns = columns)\n",
    "    # columns.append(\"label\")\n",
    "\n",
    "glcm_R = get_glcm_channel(X,'R')\n",
    "glcm_G = get_glcm_channel(X,'G')\n",
    "glcm_B = get_glcm_channel(X,'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "new_df = pd.concat([df,glcm_R,glcm_G,glcm_B], axis=1)\n",
    "X = new_df.iloc[:, :-1].values\n",
    "# y = new_df.iloc[:, -1].values\n",
    "y = np.asarray(labels)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10, weights='distance')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81 18]\n",
      " [26 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   FriedFood       0.76      0.82      0.79        99\n",
      "        Meat       0.81      0.74      0.77       101\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.78      0.78      0.78       200\n",
      "weighted avg       0.78      0.78      0.78       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Acer/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "def load_split_train_test(datadir, valid_size = .3):\n",
    "    train_transforms = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                           transforms.CenterCrop(224),\n",
    "                                           transforms.ToTensor(),\n",
    "                                       ])\n",
    "    test_transforms = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                      ])\n",
    "    \n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir,\n",
    "                    transform=test_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    \n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler)\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "data_dir = \"./data/training\"\n",
    "trainloader, testloader = load_split_train_test(data_dir, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.classifier[0] = nn.Dropout(p=0.5, inplace=False)\n",
    "model.classifier[1] = nn.Linear(1280, 1000, bias = True)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "model.to(device)\n",
    "counta = 0\n",
    "countb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3.. Train loss: 21.051.. Test loss: 0.695.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 8.841.. Test loss: 19.655.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 6.022.. Test loss: 19.884.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 9.944.. Test loss: 8.117.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 2.619.. Test loss: 4.692.. Train accuracy: 0.600.. Test accuracy: 0.550\n",
      "Epoch 1/3.. Train loss: 1.498.. Test loss: 28.526.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 2.764.. Test loss: 5.318.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.829.. Test loss: 2.255.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 2.589.. Test loss: 2.281.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.040.. Test loss: 1.567.. Train accuracy: 0.500.. Test accuracy: 0.450\n",
      "Epoch 1/3.. Train loss: 1.571.. Test loss: 9.445.. Train accuracy: 0.700.. Test accuracy: 0.460\n",
      "Epoch 1/3.. Train loss: 2.008.. Test loss: 2.483.. Train accuracy: 0.500.. Test accuracy: 0.490\n",
      "Epoch 1/3.. Train loss: 1.748.. Test loss: 2.688.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.265.. Test loss: 2.049.. Train accuracy: 0.200.. Test accuracy: 0.530\n",
      "Epoch 1/3.. Train loss: 0.893.. Test loss: 12.484.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 2.839.. Test loss: 21.243.. Train accuracy: 0.200.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 4.142.. Test loss: 8.172.. Train accuracy: 0.400.. Test accuracy: 0.490\n",
      "Epoch 1/3.. Train loss: 4.987.. Test loss: 5.123.. Train accuracy: 0.300.. Test accuracy: 0.560\n",
      "Epoch 1/3.. Train loss: 7.548.. Test loss: 10.737.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 2.200.. Test loss: 4.262.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.190.. Test loss: 0.978.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 0.728.. Test loss: 1.264.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.042.. Test loss: 1.075.. Train accuracy: 0.300.. Test accuracy: 0.530\n",
      "Epoch 1/3.. Train loss: 0.690.. Test loss: 3.883.. Train accuracy: 0.600.. Test accuracy: 0.540\n",
      "Epoch 1/3.. Train loss: 1.010.. Test loss: 1.271.. Train accuracy: 0.500.. Test accuracy: 0.510\n",
      "Epoch 1/3.. Train loss: 1.306.. Test loss: 7.944.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 0.660.. Test loss: 3.818.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.014.. Test loss: 0.704.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 4.667.. Test loss: 0.713.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 0.659.. Test loss: 1.026.. Train accuracy: 0.800.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.171.. Test loss: 0.669.. Train accuracy: 0.500.. Test accuracy: 0.620\n",
      "Epoch 1/3.. Train loss: 0.894.. Test loss: 2.985.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.390.. Test loss: 1.569.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.532.. Test loss: 2.307.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.493.. Test loss: 0.715.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 2.853.. Test loss: 75.431.. Train accuracy: 0.200.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 4.091.. Test loss: 57.823.. Train accuracy: 0.700.. Test accuracy: 0.490\n",
      "Epoch 1/3.. Train loss: 10.542.. Test loss: 17.591.. Train accuracy: 0.400.. Test accuracy: 0.440\n",
      "Epoch 1/3.. Train loss: 4.278.. Test loss: 3.986.. Train accuracy: 0.700.. Test accuracy: 0.530\n",
      "Epoch 1/3.. Train loss: 9.141.. Test loss: 7.281.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 3.140.. Test loss: 19.848.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 4.843.. Test loss: 5.255.. Train accuracy: 0.300.. Test accuracy: 0.530\n",
      "Epoch 1/3.. Train loss: 2.793.. Test loss: 2.603.. Train accuracy: 0.500.. Test accuracy: 0.550\n",
      "Epoch 1/3.. Train loss: 2.008.. Test loss: 2.197.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.576.. Test loss: 1.055.. Train accuracy: 0.400.. Test accuracy: 0.490\n",
      "Epoch 1/3.. Train loss: 2.510.. Test loss: 0.706.. Train accuracy: 0.500.. Test accuracy: 0.460\n",
      "Epoch 1/3.. Train loss: 1.431.. Test loss: 0.718.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.768.. Test loss: 2.481.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.531.. Test loss: 1.278.. Train accuracy: 0.600.. Test accuracy: 0.420\n",
      "Epoch 1/3.. Train loss: 1.233.. Test loss: 1.141.. Train accuracy: 0.700.. Test accuracy: 0.480\n",
      "Epoch 1/3.. Train loss: 1.539.. Test loss: 1.160.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.339.. Test loss: 0.663.. Train accuracy: 0.300.. Test accuracy: 0.580\n",
      "Epoch 1/3.. Train loss: 0.883.. Test loss: 0.737.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 0.794.. Test loss: 0.791.. Train accuracy: 0.600.. Test accuracy: 0.520\n",
      "Epoch 1/3.. Train loss: 0.884.. Test loss: 1.664.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.058.. Test loss: 0.676.. Train accuracy: 0.300.. Test accuracy: 0.630\n",
      "Epoch 1/3.. Train loss: 0.908.. Test loss: 0.703.. Train accuracy: 0.500.. Test accuracy: 0.420\n",
      "Epoch 1/3.. Train loss: 0.942.. Test loss: 0.825.. Train accuracy: 0.300.. Test accuracy: 0.570\n",
      "Epoch 1/3.. Train loss: 0.569.. Test loss: 2.837.. Train accuracy: 0.900.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 2.715.. Test loss: 0.879.. Train accuracy: 0.500.. Test accuracy: 0.470\n",
      "Epoch 1/3.. Train loss: 1.522.. Test loss: 0.727.. Train accuracy: 0.800.. Test accuracy: 0.510\n",
      "Epoch 1/3.. Train loss: 12.684.. Test loss: 11.236.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 44.643.. Test loss: 76.095.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 75.999.. Test loss: 719.180.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 15.311.. Test loss: 243.020.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 8.669.. Test loss: 41.724.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 8.825.. Test loss: 59.443.. Train accuracy: 0.600.. Test accuracy: 0.480\n",
      "Epoch 1/3.. Train loss: 3.582.. Test loss: 2.051.. Train accuracy: 0.600.. Test accuracy: 0.510\n",
      "Epoch 1/3.. Train loss: 1.408.. Test loss: 0.959.. Train accuracy: 0.200.. Test accuracy: 0.460\n",
      "Epoch 1/3.. Train loss: 1.571.. Test loss: 0.843.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 0.678.. Test loss: 0.871.. Train accuracy: 0.700.. Test accuracy: 0.510\n",
      "Epoch 1/3.. Train loss: 0.939.. Test loss: 1.570.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.339.. Test loss: 0.700.. Train accuracy: 0.300.. Test accuracy: 0.490\n",
      "Epoch 1/3.. Train loss: 0.572.. Test loss: 0.722.. Train accuracy: 0.500.. Test accuracy: 0.490\n",
      "Epoch 1/3.. Train loss: 0.918.. Test loss: 0.719.. Train accuracy: 0.400.. Test accuracy: 0.540\n",
      "Epoch 1/3.. Train loss: 1.020.. Test loss: 0.787.. Train accuracy: 0.400.. Test accuracy: 0.480\n",
      "Epoch 1/3.. Train loss: 1.057.. Test loss: 1.475.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.751.. Test loss: 0.726.. Train accuracy: 0.200.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 1.586.. Test loss: 1.798.. Train accuracy: 0.400.. Test accuracy: 0.510\n",
      "Epoch 1/3.. Train loss: 3.046.. Test loss: 0.940.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 0.610.. Test loss: 1.082.. Train accuracy: 0.700.. Test accuracy: 0.550\n",
      "Epoch 1/3.. Train loss: 2.968.. Test loss: 2.883.. Train accuracy: 0.500.. Test accuracy: 0.580\n",
      "Epoch 1/3.. Train loss: 4.019.. Test loss: 0.760.. Train accuracy: 0.400.. Test accuracy: 0.490\n",
      "Epoch 1/3.. Train loss: 1.791.. Test loss: 1.457.. Train accuracy: 0.600.. Test accuracy: 0.510\n",
      "Epoch 1/3.. Train loss: 1.595.. Test loss: 1.750.. Train accuracy: 0.300.. Test accuracy: 0.530\n",
      "Epoch 1/3.. Train loss: 2.195.. Test loss: 0.725.. Train accuracy: 0.200.. Test accuracy: 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3.. Train loss: 0.807.. Test loss: 1.145.. Train accuracy: 0.500.. Test accuracy: 0.570\n",
      "Epoch 1/3.. Train loss: 1.187.. Test loss: 0.731.. Train accuracy: 0.400.. Test accuracy: 0.490\n",
      "Epoch 1/3.. Train loss: 0.823.. Test loss: 0.762.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 1/3.. Train loss: 0.881.. Test loss: 1.107.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.841.. Test loss: 0.808.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.863.. Test loss: 0.757.. Train accuracy: 0.500.. Test accuracy: 0.460\n",
      "Epoch 2/3.. Train loss: 1.050.. Test loss: 0.753.. Train accuracy: 0.700.. Test accuracy: 0.540\n",
      "Epoch 2/3.. Train loss: 1.036.. Test loss: 0.697.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.932.. Test loss: 0.717.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.777.. Test loss: 0.726.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.826.. Test loss: 0.693.. Train accuracy: 0.500.. Test accuracy: 0.520\n",
      "Epoch 2/3.. Train loss: 0.358.. Test loss: 1.743.. Train accuracy: 0.800.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.406.. Test loss: 0.687.. Train accuracy: 0.500.. Test accuracy: 0.550\n",
      "Epoch 2/3.. Train loss: 0.710.. Test loss: 0.837.. Train accuracy: 0.700.. Test accuracy: 0.560\n",
      "Epoch 2/3.. Train loss: 1.106.. Test loss: 1.483.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.957.. Test loss: 2.375.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 2.035.. Test loss: 0.859.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.236.. Test loss: 1.184.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.980.. Test loss: 0.687.. Train accuracy: 0.200.. Test accuracy: 0.600\n",
      "Epoch 2/3.. Train loss: 0.853.. Test loss: 0.926.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.767.. Test loss: 0.698.. Train accuracy: 0.600.. Test accuracy: 0.560\n",
      "Epoch 2/3.. Train loss: 0.755.. Test loss: 0.738.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.702.. Test loss: 0.698.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.926.. Test loss: 0.843.. Train accuracy: 0.200.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.847.. Test loss: 0.733.. Train accuracy: 0.700.. Test accuracy: 0.550\n",
      "Epoch 2/3.. Train loss: 1.043.. Test loss: 0.873.. Train accuracy: 0.300.. Test accuracy: 0.530\n",
      "Epoch 2/3.. Train loss: 0.905.. Test loss: 0.929.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.329.. Test loss: 0.774.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.966.. Test loss: 0.741.. Train accuracy: 0.200.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.806.. Test loss: 0.698.. Train accuracy: 0.600.. Test accuracy: 0.470\n",
      "Epoch 2/3.. Train loss: 1.086.. Test loss: 0.799.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.613.. Test loss: 0.806.. Train accuracy: 0.800.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.311.. Test loss: 0.729.. Train accuracy: 0.600.. Test accuracy: 0.460\n",
      "Epoch 2/3.. Train loss: 0.980.. Test loss: 0.870.. Train accuracy: 0.800.. Test accuracy: 0.540\n",
      "Epoch 2/3.. Train loss: 2.394.. Test loss: 0.776.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.982.. Test loss: 0.812.. Train accuracy: 0.700.. Test accuracy: 0.490\n",
      "Epoch 2/3.. Train loss: 0.888.. Test loss: 0.718.. Train accuracy: 0.300.. Test accuracy: 0.490\n",
      "Epoch 2/3.. Train loss: 1.123.. Test loss: 0.867.. Train accuracy: 0.300.. Test accuracy: 0.440\n",
      "Epoch 2/3.. Train loss: 0.956.. Test loss: 0.692.. Train accuracy: 0.300.. Test accuracy: 0.560\n",
      "Epoch 2/3.. Train loss: 0.732.. Test loss: 0.722.. Train accuracy: 0.700.. Test accuracy: 0.580\n",
      "Epoch 2/3.. Train loss: 1.122.. Test loss: 0.924.. Train accuracy: 0.300.. Test accuracy: 0.520\n",
      "Epoch 2/3.. Train loss: 1.005.. Test loss: 0.799.. Train accuracy: 0.600.. Test accuracy: 0.550\n",
      "Epoch 2/3.. Train loss: 0.934.. Test loss: 0.786.. Train accuracy: 0.500.. Test accuracy: 0.440\n",
      "Epoch 2/3.. Train loss: 1.030.. Test loss: 0.755.. Train accuracy: 0.500.. Test accuracy: 0.470\n",
      "Epoch 2/3.. Train loss: 0.846.. Test loss: 0.719.. Train accuracy: 0.700.. Test accuracy: 0.510\n",
      "Epoch 2/3.. Train loss: 1.326.. Test loss: 0.699.. Train accuracy: 0.500.. Test accuracy: 0.550\n",
      "Epoch 2/3.. Train loss: 1.557.. Test loss: 0.865.. Train accuracy: 0.500.. Test accuracy: 0.430\n",
      "Epoch 2/3.. Train loss: 1.695.. Test loss: 0.826.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.993.. Test loss: 0.792.. Train accuracy: 0.500.. Test accuracy: 0.440\n",
      "Epoch 2/3.. Train loss: 1.514.. Test loss: 1.153.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.549.. Test loss: 0.754.. Train accuracy: 0.500.. Test accuracy: 0.590\n",
      "Epoch 2/3.. Train loss: 1.125.. Test loss: 0.764.. Train accuracy: 0.400.. Test accuracy: 0.560\n",
      "Epoch 2/3.. Train loss: 0.889.. Test loss: 0.692.. Train accuracy: 0.300.. Test accuracy: 0.530\n",
      "Epoch 2/3.. Train loss: 0.776.. Test loss: 1.027.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.198.. Test loss: 0.749.. Train accuracy: 0.200.. Test accuracy: 0.430\n",
      "Epoch 2/3.. Train loss: 1.103.. Test loss: 1.010.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.232.. Test loss: 0.756.. Train accuracy: 0.400.. Test accuracy: 0.470\n",
      "Epoch 2/3.. Train loss: 1.027.. Test loss: 0.698.. Train accuracy: 0.400.. Test accuracy: 0.590\n",
      "Epoch 2/3.. Train loss: 0.844.. Test loss: 0.714.. Train accuracy: 0.400.. Test accuracy: 0.510\n",
      "Epoch 2/3.. Train loss: 1.240.. Test loss: 0.744.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.702.. Test loss: 0.686.. Train accuracy: 0.600.. Test accuracy: 0.570\n",
      "Epoch 2/3.. Train loss: 0.973.. Test loss: 0.837.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.490.. Test loss: 0.692.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.714.. Test loss: 0.871.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.368.. Test loss: 0.695.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.057.. Test loss: 1.017.. Train accuracy: 0.300.. Test accuracy: 0.490\n",
      "Epoch 2/3.. Train loss: 1.165.. Test loss: 0.785.. Train accuracy: 0.600.. Test accuracy: 0.490\n",
      "Epoch 2/3.. Train loss: 1.058.. Test loss: 1.028.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.221.. Test loss: 0.754.. Train accuracy: 0.500.. Test accuracy: 0.410\n",
      "Epoch 2/3.. Train loss: 1.195.. Test loss: 1.017.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 1.240.. Test loss: 0.761.. Train accuracy: 0.500.. Test accuracy: 0.460\n",
      "Epoch 2/3.. Train loss: 1.084.. Test loss: 0.899.. Train accuracy: 0.600.. Test accuracy: 0.550\n",
      "Epoch 2/3.. Train loss: 1.218.. Test loss: 0.715.. Train accuracy: 0.300.. Test accuracy: 0.510\n",
      "Epoch 2/3.. Train loss: 1.577.. Test loss: 1.293.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 2.798.. Test loss: 3.381.. Train accuracy: 0.700.. Test accuracy: 0.490\n",
      "Epoch 2/3.. Train loss: 1.430.. Test loss: 0.880.. Train accuracy: 0.400.. Test accuracy: 0.510\n",
      "Epoch 2/3.. Train loss: 0.927.. Test loss: 1.142.. Train accuracy: 0.400.. Test accuracy: 0.530\n",
      "Epoch 2/3.. Train loss: 0.990.. Test loss: 0.773.. Train accuracy: 0.400.. Test accuracy: 0.510\n",
      "Epoch 2/3.. Train loss: 0.888.. Test loss: 0.753.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.975.. Test loss: 0.697.. Train accuracy: 0.300.. Test accuracy: 0.490\n",
      "Epoch 2/3.. Train loss: 0.901.. Test loss: 0.717.. Train accuracy: 0.300.. Test accuracy: 0.480\n",
      "Epoch 2/3.. Train loss: 1.275.. Test loss: 0.713.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.688.. Test loss: 0.703.. Train accuracy: 0.500.. Test accuracy: 0.420\n",
      "Epoch 2/3.. Train loss: 1.086.. Test loss: 0.721.. Train accuracy: 0.200.. Test accuracy: 0.490\n",
      "Epoch 2/3.. Train loss: 0.790.. Test loss: 0.843.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.656.. Test loss: 0.793.. Train accuracy: 0.700.. Test accuracy: 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3.. Train loss: 0.837.. Test loss: 0.755.. Train accuracy: 0.800.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 0.598.. Test loss: 0.758.. Train accuracy: 0.700.. Test accuracy: 0.490\n",
      "Epoch 2/3.. Train loss: 0.614.. Test loss: 0.749.. Train accuracy: 0.600.. Test accuracy: 0.510\n",
      "Epoch 2/3.. Train loss: 1.273.. Test loss: 1.011.. Train accuracy: 0.700.. Test accuracy: 0.460\n",
      "Epoch 2/3.. Train loss: 1.450.. Test loss: 1.824.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 2/3.. Train loss: 2.276.. Test loss: 0.874.. Train accuracy: 0.500.. Test accuracy: 0.430\n",
      "Epoch 2/3.. Train loss: 0.870.. Test loss: 0.728.. Train accuracy: 0.500.. Test accuracy: 0.400\n",
      "Epoch 2/3.. Train loss: 0.887.. Test loss: 0.934.. Train accuracy: 0.400.. Test accuracy: 0.440\n",
      "Epoch 3/3.. Train loss: 0.920.. Test loss: 1.368.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 3.174.. Test loss: 2.955.. Train accuracy: 0.800.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 2.564.. Test loss: 3.860.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 5.267.. Test loss: 0.844.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 2.207.. Test loss: 3.660.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 2.429.. Test loss: 6.354.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 2.195.. Test loss: 1.270.. Train accuracy: 0.400.. Test accuracy: 0.550\n",
      "Epoch 3/3.. Train loss: 1.199.. Test loss: 0.751.. Train accuracy: 0.300.. Test accuracy: 0.610\n",
      "Epoch 3/3.. Train loss: 1.119.. Test loss: 0.649.. Train accuracy: 0.500.. Test accuracy: 0.620\n",
      "Epoch 3/3.. Train loss: 0.738.. Test loss: 0.693.. Train accuracy: 0.400.. Test accuracy: 0.580\n",
      "Epoch 3/3.. Train loss: 0.881.. Test loss: 0.721.. Train accuracy: 0.300.. Test accuracy: 0.570\n",
      "Epoch 3/3.. Train loss: 1.211.. Test loss: 0.795.. Train accuracy: 0.400.. Test accuracy: 0.450\n",
      "Epoch 3/3.. Train loss: 0.834.. Test loss: 1.469.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.171.. Test loss: 0.723.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.820.. Test loss: 0.836.. Train accuracy: 0.300.. Test accuracy: 0.510\n",
      "Epoch 3/3.. Train loss: 0.964.. Test loss: 1.184.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.815.. Test loss: 0.953.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.514.. Test loss: 1.270.. Train accuracy: 0.800.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.687.. Test loss: 1.046.. Train accuracy: 0.400.. Test accuracy: 0.490\n",
      "Epoch 3/3.. Train loss: 1.383.. Test loss: 0.678.. Train accuracy: 0.300.. Test accuracy: 0.610\n",
      "Epoch 3/3.. Train loss: 0.849.. Test loss: 0.884.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.378.. Test loss: 0.739.. Train accuracy: 0.200.. Test accuracy: 0.550\n",
      "Epoch 3/3.. Train loss: 1.203.. Test loss: 0.695.. Train accuracy: 0.500.. Test accuracy: 0.510\n",
      "Epoch 3/3.. Train loss: 0.901.. Test loss: 0.705.. Train accuracy: 0.600.. Test accuracy: 0.460\n",
      "Epoch 3/3.. Train loss: 0.804.. Test loss: 0.789.. Train accuracy: 0.700.. Test accuracy: 0.490\n",
      "Epoch 3/3.. Train loss: 1.104.. Test loss: 0.685.. Train accuracy: 0.600.. Test accuracy: 0.570\n",
      "Epoch 3/3.. Train loss: 0.730.. Test loss: 0.725.. Train accuracy: 0.700.. Test accuracy: 0.490\n",
      "Epoch 3/3.. Train loss: 1.166.. Test loss: 0.721.. Train accuracy: 0.100.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.849.. Test loss: 0.698.. Train accuracy: 0.500.. Test accuracy: 0.530\n",
      "Epoch 3/3.. Train loss: 0.618.. Test loss: 0.699.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.019.. Test loss: 0.957.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.056.. Test loss: 0.829.. Train accuracy: 0.600.. Test accuracy: 0.510\n",
      "Epoch 3/3.. Train loss: 0.898.. Test loss: 0.693.. Train accuracy: 0.300.. Test accuracy: 0.510\n",
      "Epoch 3/3.. Train loss: 0.784.. Test loss: 0.730.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.836.. Test loss: 0.727.. Train accuracy: 0.600.. Test accuracy: 0.510\n",
      "Epoch 3/3.. Train loss: 0.714.. Test loss: 0.716.. Train accuracy: 0.500.. Test accuracy: 0.540\n",
      "Epoch 3/3.. Train loss: 0.807.. Test loss: 0.722.. Train accuracy: 0.400.. Test accuracy: 0.480\n",
      "Epoch 3/3.. Train loss: 0.669.. Test loss: 0.773.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.780.. Test loss: 0.718.. Train accuracy: 0.300.. Test accuracy: 0.540\n",
      "Epoch 3/3.. Train loss: 0.747.. Test loss: 0.826.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.717.. Test loss: 0.737.. Train accuracy: 0.700.. Test accuracy: 0.550\n",
      "Epoch 3/3.. Train loss: 0.961.. Test loss: 0.692.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.811.. Test loss: 0.715.. Train accuracy: 0.300.. Test accuracy: 0.490\n",
      "Epoch 3/3.. Train loss: 0.781.. Test loss: 0.718.. Train accuracy: 0.300.. Test accuracy: 0.490\n",
      "Epoch 3/3.. Train loss: 0.526.. Test loss: 1.415.. Train accuracy: 0.900.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.061.. Test loss: 0.702.. Train accuracy: 0.800.. Test accuracy: 0.420\n",
      "Epoch 3/3.. Train loss: 0.781.. Test loss: 0.740.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.572.. Test loss: 1.138.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.242.. Test loss: 0.676.. Train accuracy: 0.500.. Test accuracy: 0.580\n",
      "Epoch 3/3.. Train loss: 0.706.. Test loss: 0.688.. Train accuracy: 0.700.. Test accuracy: 0.530\n",
      "Epoch 3/3.. Train loss: 1.382.. Test loss: 0.806.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.885.. Test loss: 0.701.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.950.. Test loss: 0.724.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.873.. Test loss: 0.727.. Train accuracy: 0.600.. Test accuracy: 0.480\n",
      "Epoch 3/3.. Train loss: 0.743.. Test loss: 0.763.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.819.. Test loss: 0.757.. Train accuracy: 0.300.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.920.. Test loss: 0.703.. Train accuracy: 0.500.. Test accuracy: 0.560\n",
      "Epoch 3/3.. Train loss: 0.808.. Test loss: 0.993.. Train accuracy: 0.500.. Test accuracy: 0.480\n",
      "Epoch 3/3.. Train loss: 0.873.. Test loss: 0.736.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.818.. Test loss: 0.713.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.902.. Test loss: 0.750.. Train accuracy: 0.600.. Test accuracy: 0.510\n",
      "Epoch 3/3.. Train loss: 0.816.. Test loss: 0.879.. Train accuracy: 0.300.. Test accuracy: 0.520\n",
      "Epoch 3/3.. Train loss: 0.900.. Test loss: 0.810.. Train accuracy: 0.300.. Test accuracy: 0.480\n",
      "Epoch 3/3.. Train loss: 0.786.. Test loss: 1.000.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.917.. Test loss: 1.049.. Train accuracy: 0.400.. Test accuracy: 0.430\n",
      "Epoch 3/3.. Train loss: 1.007.. Test loss: 1.091.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.890.. Test loss: 0.693.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.948.. Test loss: 0.702.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.740.. Test loss: 0.687.. Train accuracy: 0.400.. Test accuracy: 0.520\n",
      "Epoch 3/3.. Train loss: 0.481.. Test loss: 1.282.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.297.. Test loss: 0.683.. Train accuracy: 0.600.. Test accuracy: 0.530\n",
      "Epoch 3/3.. Train loss: 1.282.. Test loss: 0.883.. Train accuracy: 0.200.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.905.. Test loss: 0.704.. Train accuracy: 0.400.. Test accuracy: 0.510\n",
      "Epoch 3/3.. Train loss: 0.904.. Test loss: 0.866.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.916.. Test loss: 0.733.. Train accuracy: 0.400.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.857.. Test loss: 0.728.. Train accuracy: 0.400.. Test accuracy: 0.450\n",
      "Epoch 3/3.. Train loss: 0.813.. Test loss: 0.854.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.948.. Test loss: 0.840.. Train accuracy: 0.400.. Test accuracy: 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3.. Train loss: 0.793.. Test loss: 0.741.. Train accuracy: 0.400.. Test accuracy: 0.510\n",
      "Epoch 3/3.. Train loss: 0.650.. Test loss: 1.247.. Train accuracy: 0.700.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.974.. Test loss: 0.799.. Train accuracy: 0.300.. Test accuracy: 0.420\n",
      "Epoch 3/3.. Train loss: 0.808.. Test loss: 0.713.. Train accuracy: 0.200.. Test accuracy: 0.450\n",
      "Epoch 3/3.. Train loss: 0.805.. Test loss: 0.862.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.637.. Test loss: 1.257.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.022.. Test loss: 0.682.. Train accuracy: 0.600.. Test accuracy: 0.540\n",
      "Epoch 3/3.. Train loss: 0.915.. Test loss: 0.949.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.087.. Test loss: 0.888.. Train accuracy: 0.600.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 1.458.. Test loss: 1.058.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.991.. Test loss: 0.731.. Train accuracy: 0.500.. Test accuracy: 0.500\n",
      "Epoch 3/3.. Train loss: 0.765.. Test loss: 0.700.. Train accuracy: 0.400.. Test accuracy: 0.470\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "train_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    for train_inputs, train_labels in trainloader:\n",
    "        steps += 1\n",
    "        train_inputs, train_labels = train_inputs.to(device), train_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        train_logps = model(train_inputs)\n",
    "        train_loss = criterion(train_logps, train_labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += train_loss.item()\n",
    "        \n",
    "        train_ps = torch.exp(train_logps)\n",
    "        train_top_p, train_top_class = train_ps.topk(1, dim=1)\n",
    "        train_equals = train_top_class == train_labels.view(*train_top_class.shape)\n",
    "        train_accuracy += torch.mean(train_equals.type(torch.FloatTensor)).item() \n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device),labels.to(device)\n",
    "                    logps = model(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/print_every)\n",
    "            test_losses.append(test_loss/len(testloader))     \n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Train accuracy: {train_accuracy/print_every:.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            train_accuracy = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3506874\n"
     ]
    }
   ],
   "source": [
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
