{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/401.jpg\n",
      "./data/training/Fried food/402.jpg\n",
      "./data/training/Fried food/403.jpg\n",
      "./data/training/Fried food/404.jpg\n",
      "./data/training/Fried food/405.jpg\n",
      "./data/training/Fried food/406.jpg\n",
      "./data/training/Fried food/407.jpg\n",
      "./data/training/Fried food/408.jpg\n",
      "./data/training/Fried food/409.jpg\n",
      "./data/training/Fried food/41.jpg\n",
      "./data/training/Fried food/410.jpg\n",
      "./data/training/Fried food/411.jpg\n",
      "./data/training/Fried food/412.jpg\n",
      "./data/training/Fried food/413.jpg\n",
      "./data/training/Fried food/414.jpg\n",
      "./data/training/Fried food/415.jpg\n",
      "./data/training/Fried food/416.jpg\n",
      "./data/training/Fried food/417.jpg\n",
      "./data/training/Fried food/418.jpg\n",
      "./data/training/Fried food/419.jpg\n",
      "./data/training/Fried food/42.jpg\n",
      "./data/training/Fried food/420.jpg\n",
      "./data/training/Fried food/421.jpg\n",
      "./data/training/Fried food/422.jpg\n",
      "./data/training/Fried food/423.jpg\n",
      "./data/training/Fried food/424.jpg\n",
      "./data/training/Fried food/425.jpg\n",
      "./data/training/Fried food/426.jpg\n",
      "./data/training/Fried food/427.jpg\n",
      "./data/training/Fried food/428.jpg\n",
      "./data/training/Fried food/429.jpg\n",
      "./data/training/Fried food/43.jpg\n",
      "./data/training/Fried food/430.jpg\n",
      "./data/training/Fried food/431.jpg\n",
      "./data/training/Fried food/432.jpg\n",
      "./data/training/Fried food/433.jpg\n",
      "./data/training/Fried food/434.jpg\n",
      "./data/training/Fried food/435.jpg\n",
      "./data/training/Fried food/436.jpg\n",
      "./data/training/Fried food/437.jpg\n",
      "./data/training/Fried food/438.jpg\n",
      "./data/training/Fried food/439.jpg\n",
      "./data/training/Fried food/44.jpg\n",
      "./data/training/Fried food/440.jpg\n",
      "./data/training/Fried food/441.jpg\n",
      "./data/training/Fried food/442.jpg\n",
      "./data/training/Fried food/443.jpg\n",
      "./data/training/Fried food/444.jpg\n",
      "./data/training/Fried food/445.jpg\n",
      "./data/training/Fried food/446.jpg\n",
      "./data/training/Fried food/447.jpg\n",
      "./data/training/Fried food/448.jpg\n",
      "./data/training/Fried food/449.jpg\n",
      "./data/training/Fried food/45.jpg\n",
      "./data/training/Fried food/450.jpg\n",
      "./data/training/Fried food/451.jpg\n",
      "./data/training/Fried food/452.jpg\n",
      "./data/training/Fried food/453.jpg\n",
      "./data/training/Fried food/454.jpg\n",
      "./data/training/Fried food/455.jpg\n",
      "./data/training/Fried food/456.jpg\n",
      "./data/training/Fried food/457.jpg\n",
      "./data/training/Fried food/458.jpg\n",
      "./data/training/Fried food/459.jpg\n",
      "./data/training/Fried food/46.jpg\n",
      "./data/training/Fried food/460.jpg\n",
      "./data/training/Fried food/461.jpg\n",
      "./data/training/Fried food/462.jpg\n",
      "./data/training/Fried food/463.jpg\n",
      "./data/training/Fried food/464.jpg\n",
      "./data/training/Fried food/465.jpg\n",
      "./data/training/Fried food/466.jpg\n",
      "./data/training/Fried food/467.jpg\n",
      "./data/training/Fried food/468.jpg\n",
      "./data/training/Fried food/469.jpg\n",
      "./data/training/Fried food/47.jpg\n",
      "./data/training/Fried food/470.jpg\n",
      "./data/training/Fried food/471.jpg\n",
      "./data/training/Fried food/472.jpg\n",
      "./data/training/Fried food/473.jpg\n",
      "./data/training/Fried food/474.jpg\n",
      "./data/training/Fried food/475.jpg\n",
      "./data/training/Fried food/476.jpg\n",
      "./data/training/Fried food/477.jpg\n",
      "./data/training/Fried food/478.jpg\n",
      "./data/training/Fried food/479.jpg\n",
      "./data/training/Fried food/48.jpg\n",
      "./data/training/Fried food/480.jpg\n",
      "./data/training/Fried food/481.jpg\n",
      "./data/training/Fried food/482.jpg\n",
      "./data/training/Fried food/483.jpg\n",
      "./data/training/Fried food/484.jpg\n",
      "./data/training/Fried food/485.jpg\n",
      "./data/training/Fried food/486.jpg\n",
      "./data/training/Fried food/487.jpg\n",
      "./data/training/Fried food/488.jpg\n",
      "./data/training/Fried food/489.jpg\n",
      "./data/training/Fried food/49.jpg\n",
      "./data/training/Fried food/490.jpg\n",
      "./data/training/Fried food/491.jpg\n",
      "./data/training/Fried food/492.jpg\n",
      "./data/training/Fried food/493.jpg\n",
      "./data/training/Fried food/494.jpg\n",
      "./data/training/Fried food/495.jpg\n",
      "./data/training/Fried food/496.jpg\n",
      "./data/training/Fried food/497.jpg\n",
      "./data/training/Fried food/498.jpg\n",
      "./data/training/Fried food/499.jpg\n",
      "./data/training/Fried food/5.jpg\n",
      "./data/training/Fried food/50.jpg\n",
      "./data/training/Fried food/51.jpg\n",
      "./data/training/Fried food/52.jpg\n",
      "./data/training/Fried food/53.jpg\n",
      "./data/training/Fried food/54.jpg\n",
      "./data/training/Fried food/55.jpg\n",
      "./data/training/Fried food/56.jpg\n",
      "./data/training/Fried food/57.jpg\n",
      "./data/training/Fried food/58.jpg\n",
      "./data/training/Fried food/59.jpg\n",
      "./data/training/Fried food/6.jpg\n",
      "./data/training/Fried food/60.jpg\n",
      "./data/training/Fried food/61.jpg\n",
      "./data/training/Fried food/62.jpg\n",
      "./data/training/Fried food/63.jpg\n",
      "./data/training/Fried food/64.jpg\n",
      "./data/training/Fried food/65.jpg\n",
      "./data/training/Fried food/66.jpg\n",
      "./data/training/Fried food/67.jpg\n",
      "./data/training/Fried food/68.jpg\n",
      "./data/training/Fried food/69.jpg\n",
      "./data/training/Fried food/7.jpg\n",
      "./data/training/Fried food/70.jpg\n",
      "./data/training/Fried food/71.jpg\n",
      "./data/training/Fried food/72.jpg\n",
      "./data/training/Fried food/73.jpg\n",
      "./data/training/Fried food/74.jpg\n",
      "./data/training/Fried food/75.jpg\n",
      "./data/training/Fried food/76.jpg\n",
      "./data/training/Fried food/77.jpg\n",
      "./data/training/Fried food/78.jpg\n",
      "./data/training/Fried food/79.jpg\n",
      "./data/training/Fried food/8.jpg\n",
      "./data/training/Fried food/80.jpg\n",
      "./data/training/Fried food/81.jpg\n",
      "./data/training/Fried food/82.jpg\n",
      "./data/training/Fried food/83.jpg\n",
      "./data/training/Fried food/84.jpg\n",
      "./data/training/Fried food/85.jpg\n",
      "./data/training/Fried food/86.jpg\n",
      "./data/training/Fried food/87.jpg\n",
      "./data/training/Fried food/88.jpg\n",
      "./data/training/Fried food/89.jpg\n",
      "./data/training/Fried food/9.jpg\n",
      "./data/training/Fried food/90.jpg\n",
      "./data/training/Fried food/91.jpg\n",
      "./data/training/Fried food/92.jpg\n",
      "./data/training/Fried food/93.jpg\n",
      "./data/training/Fried food/94.jpg\n",
      "./data/training/Fried food/95.jpg\n",
      "./data/training/Fried food/96.jpg\n",
      "./data/training/Fried food/97.jpg\n",
      "./data/training/Fried food/98.jpg\n",
      "./data/training/Fried food/99.jpg\n",
      "./data/training/Meat/0.jpg\n",
      "./data/training/Meat/1.jpg\n",
      "./data/training/Meat/10.jpg\n",
      "./data/training/Meat/100.jpg\n",
      "./data/training/Meat/101.jpg\n",
      "./data/training/Meat/102.jpg\n",
      "./data/training/Meat/103.jpg\n",
      "./data/training/Meat/104.jpg\n",
      "./data/training/Meat/105.jpg\n",
      "./data/training/Meat/106.jpg\n",
      "./data/training/Meat/107.jpg\n",
      "./data/training/Meat/108.jpg\n",
      "./data/training/Meat/109.jpg\n",
      "./data/training/Meat/11.jpg\n",
      "./data/training/Meat/110.jpg\n",
      "./data/training/Meat/111.jpg\n",
      "./data/training/Meat/112.jpg\n",
      "./data/training/Meat/113.jpg\n",
      "./data/training/Meat/114.jpg\n",
      "./data/training/Meat/115.jpg\n",
      "./data/training/Meat/116.jpg\n",
      "./data/training/Meat/117.jpg\n",
      "./data/training/Meat/118.jpg\n",
      "./data/training/Meat/119.jpg\n",
      "./data/training/Meat/12.jpg\n",
      "./data/training/Meat/120.jpg\n",
      "./data/training/Meat/121.jpg\n",
      "./data/training/Meat/122.jpg\n",
      "./data/training/Meat/123.jpg\n",
      "./data/training/Meat/124.jpg\n",
      "./data/training/Meat/125.jpg\n",
      "./data/training/Meat/126.jpg\n",
      "./data/training/Meat/127.jpg\n",
      "./data/training/Meat/128.jpg\n",
      "./data/training/Meat/129.jpg\n",
      "./data/training/Meat/13.jpg\n",
      "./data/training/Meat/130.jpg\n",
      "./data/training/Meat/131.jpg\n",
      "./data/training/Meat/132.jpg\n",
      "./data/training/Meat/133.jpg\n",
      "./data/training/Meat/134.jpg\n",
      "./data/training/Meat/135.jpg\n",
      "./data/training/Meat/136.jpg\n",
      "./data/training/Meat/137.jpg\n",
      "./data/training/Meat/138.jpg\n",
      "./data/training/Meat/139.jpg\n",
      "./data/training/Meat/14.jpg\n",
      "./data/training/Meat/140.jpg\n",
      "./data/training/Meat/141.jpg\n",
      "./data/training/Meat/142.jpg\n",
      "./data/training/Meat/143.jpg\n",
      "./data/training/Meat/144.jpg\n",
      "./data/training/Meat/145.jpg\n",
      "./data/training/Meat/146.jpg\n",
      "./data/training/Meat/147.jpg\n",
      "./data/training/Meat/148.jpg\n",
      "./data/training/Meat/149.jpg\n",
      "./data/training/Meat/15.jpg\n",
      "./data/training/Meat/150.jpg\n",
      "./data/training/Meat/151.jpg\n",
      "./data/training/Meat/152.jpg\n",
      "./data/training/Meat/153.jpg\n",
      "./data/training/Meat/154.jpg\n",
      "./data/training/Meat/155.jpg\n",
      "./data/training/Meat/156.jpg\n",
      "./data/training/Meat/157.jpg\n",
      "./data/training/Meat/158.jpg\n",
      "./data/training/Meat/159.jpg\n",
      "./data/training/Meat/16.jpg\n",
      "./data/training/Meat/160.jpg\n",
      "./data/training/Meat/161.jpg\n",
      "./data/training/Meat/162.jpg\n",
      "./data/training/Meat/163.jpg\n",
      "./data/training/Meat/164.jpg\n",
      "./data/training/Meat/165.jpg\n",
      "./data/training/Meat/166.jpg\n",
      "./data/training/Meat/167.jpg\n",
      "./data/training/Meat/168.jpg\n",
      "./data/training/Meat/169.jpg\n",
      "./data/training/Meat/17.jpg\n",
      "./data/training/Meat/170.jpg\n",
      "./data/training/Meat/171.jpg\n",
      "./data/training/Meat/172.jpg\n",
      "./data/training/Meat/173.jpg\n",
      "./data/training/Meat/174.jpg\n",
      "./data/training/Meat/175.jpg\n",
      "./data/training/Meat/176.jpg\n",
      "./data/training/Meat/177.jpg\n",
      "./data/training/Meat/178.jpg\n",
      "./data/training/Meat/179.jpg\n",
      "./data/training/Meat/18.jpg\n",
      "./data/training/Meat/180.jpg\n",
      "./data/training/Meat/181.jpg\n",
      "./data/training/Meat/182.jpg\n",
      "./data/training/Meat/183.jpg\n",
      "./data/training/Meat/184.jpg\n",
      "./data/training/Meat/185.jpg\n",
      "./data/training/Meat/186.jpg\n",
      "./data/training/Meat/187.jpg\n",
      "./data/training/Meat/188.jpg\n",
      "./data/training/Meat/189.jpg\n",
      "./data/training/Meat/19.jpg\n",
      "./data/training/Meat/190.jpg\n",
      "./data/training/Meat/191.jpg\n",
      "./data/training/Meat/192.jpg\n",
      "./data/training/Meat/193.jpg\n",
      "./data/training/Meat/194.jpg\n",
      "./data/training/Meat/195.jpg\n",
      "./data/training/Meat/196.jpg\n",
      "./data/training/Meat/197.jpg\n",
      "./data/training/Meat/198.jpg\n",
      "./data/training/Meat/199.jpg\n",
      "./data/training/Meat/2.jpg\n",
      "./data/training/Meat/20.jpg\n",
      "./data/training/Meat/200.jpg\n",
      "./data/training/Meat/201.jpg\n",
      "./data/training/Meat/202.jpg\n",
      "./data/training/Meat/203.jpg\n",
      "./data/training/Meat/204.jpg\n",
      "./data/training/Meat/205.jpg\n",
      "./data/training/Meat/206.jpg\n",
      "./data/training/Meat/207.jpg\n",
      "./data/training/Meat/208.jpg\n",
      "./data/training/Meat/209.jpg\n",
      "./data/training/Meat/21.jpg\n",
      "./data/training/Meat/210.jpg\n",
      "./data/training/Meat/211.jpg\n",
      "./data/training/Meat/212.jpg\n",
      "./data/training/Meat/213.jpg\n",
      "./data/training/Meat/214.jpg\n",
      "./data/training/Meat/215.jpg\n",
      "./data/training/Meat/216.jpg\n",
      "./data/training/Meat/217.jpg\n",
      "./data/training/Meat/218.jpg\n",
      "./data/training/Meat/219.jpg\n",
      "./data/training/Meat/22.jpg\n",
      "./data/training/Meat/220.jpg\n",
      "./data/training/Meat/221.jpg\n",
      "./data/training/Meat/222.jpg\n",
      "./data/training/Meat/223.jpg\n",
      "./data/training/Meat/224.jpg\n",
      "./data/training/Meat/225.jpg\n",
      "./data/training/Meat/226.jpg\n",
      "./data/training/Meat/227.jpg\n",
      "./data/training/Meat/228.jpg\n",
      "./data/training/Meat/229.jpg\n",
      "./data/training/Meat/23.jpg\n",
      "./data/training/Meat/230.jpg\n",
      "./data/training/Meat/231.jpg\n",
      "./data/training/Meat/232.jpg\n",
      "./data/training/Meat/233.jpg\n",
      "./data/training/Meat/234.jpg\n",
      "./data/training/Meat/235.jpg\n",
      "./data/training/Meat/236.jpg\n",
      "./data/training/Meat/237.jpg\n",
      "./data/training/Meat/238.jpg\n",
      "./data/training/Meat/239.jpg\n",
      "./data/training/Meat/24.jpg\n",
      "./data/training/Meat/240.jpg\n",
      "./data/training/Meat/241.jpg\n",
      "./data/training/Meat/242.jpg\n",
      "./data/training/Meat/243.jpg\n",
      "./data/training/Meat/244.jpg\n",
      "./data/training/Meat/245.jpg\n",
      "./data/training/Meat/246.jpg\n",
      "./data/training/Meat/247.jpg\n",
      "./data/training/Meat/248.jpg\n",
      "./data/training/Meat/249.jpg\n",
      "./data/training/Meat/25.jpg\n",
      "./data/training/Meat/250.jpg\n",
      "./data/training/Meat/251.jpg\n",
      "./data/training/Meat/252.jpg\n",
      "./data/training/Meat/253.jpg\n",
      "./data/training/Meat/254.jpg\n",
      "./data/training/Meat/255.jpg\n",
      "./data/training/Meat/256.jpg\n",
      "./data/training/Meat/257.jpg\n",
      "./data/training/Meat/258.jpg\n",
      "./data/training/Meat/259.jpg\n",
      "./data/training/Meat/26.jpg\n",
      "./data/training/Meat/260.jpg\n",
      "./data/training/Meat/261.jpg\n",
      "./data/training/Meat/262.jpg\n",
      "./data/training/Meat/263.jpg\n",
      "./data/training/Meat/264.jpg\n",
      "./data/training/Meat/265.jpg\n",
      "./data/training/Meat/266.jpg\n",
      "./data/training/Meat/267.jpg\n",
      "./data/training/Meat/268.jpg\n",
      "./data/training/Meat/269.jpg\n",
      "./data/training/Meat/27.jpg\n",
      "./data/training/Meat/270.jpg\n",
      "./data/training/Meat/271.jpg\n",
      "./data/training/Meat/272.jpg\n",
      "./data/training/Meat/273.jpg\n",
      "./data/training/Meat/274.jpg\n",
      "./data/training/Meat/275.jpg\n",
      "./data/training/Meat/276.jpg\n",
      "./data/training/Meat/277.jpg\n",
      "./data/training/Meat/278.jpg\n",
      "./data/training/Meat/279.jpg\n",
      "./data/training/Meat/28.jpg\n",
      "./data/training/Meat/280.jpg\n",
      "./data/training/Meat/281.jpg\n",
      "./data/training/Meat/282.jpg\n",
      "./data/training/Meat/283.jpg\n",
      "./data/training/Meat/284.jpg\n",
      "./data/training/Meat/285.jpg\n",
      "./data/training/Meat/286.jpg\n",
      "./data/training/Meat/287.jpg\n",
      "./data/training/Meat/288.jpg\n",
      "./data/training/Meat/289.jpg\n",
      "./data/training/Meat/29.jpg\n",
      "./data/training/Meat/290.jpg\n",
      "./data/training/Meat/291.jpg\n",
      "./data/training/Meat/292.jpg\n",
      "./data/training/Meat/293.jpg\n",
      "./data/training/Meat/294.jpg\n",
      "./data/training/Meat/295.jpg\n",
      "./data/training/Meat/296.jpg\n",
      "./data/training/Meat/297.jpg\n",
      "./data/training/Meat/298.jpg\n",
      "./data/training/Meat/299.jpg\n",
      "./data/training/Meat/3.jpg\n",
      "./data/training/Meat/30.jpg\n",
      "./data/training/Meat/300.jpg\n",
      "./data/training/Meat/301.jpg\n",
      "./data/training/Meat/302.jpg\n",
      "./data/training/Meat/303.jpg\n",
      "./data/training/Meat/304.jpg\n",
      "./data/training/Meat/305.jpg\n",
      "./data/training/Meat/306.jpg\n",
      "./data/training/Meat/307.jpg\n",
      "./data/training/Meat/308.jpg\n",
      "./data/training/Meat/309.jpg\n",
      "./data/training/Meat/31.jpg\n",
      "./data/training/Meat/310.jpg\n",
      "./data/training/Meat/311.jpg\n",
      "./data/training/Meat/312.jpg\n",
      "./data/training/Meat/313.jpg\n",
      "./data/training/Meat/314.jpg\n",
      "./data/training/Meat/315.jpg\n",
      "./data/training/Meat/316.jpg\n",
      "./data/training/Meat/317.jpg\n",
      "./data/training/Meat/318.jpg\n",
      "./data/training/Meat/319.jpg\n",
      "./data/training/Meat/32.jpg\n",
      "./data/training/Meat/320.jpg\n",
      "./data/training/Meat/321.jpg\n",
      "./data/training/Meat/322.jpg\n",
      "./data/training/Meat/323.jpg\n",
      "./data/training/Meat/324.jpg\n",
      "./data/training/Meat/325.jpg\n",
      "./data/training/Meat/326.jpg\n",
      "./data/training/Meat/327.jpg\n",
      "./data/training/Meat/328.jpg\n",
      "./data/training/Meat/329.jpg\n",
      "./data/training/Meat/33.jpg\n",
      "./data/training/Meat/330.jpg\n",
      "./data/training/Meat/331.jpg\n",
      "./data/training/Meat/332.jpg\n",
      "./data/training/Meat/333.jpg\n",
      "./data/training/Meat/334.jpg\n",
      "./data/training/Meat/335.jpg\n",
      "./data/training/Meat/336.jpg\n",
      "./data/training/Meat/337.jpg\n",
      "./data/training/Meat/338.jpg\n",
      "./data/training/Meat/339.jpg\n",
      "./data/training/Meat/34.jpg\n",
      "./data/training/Meat/340.jpg\n",
      "./data/training/Meat/341.jpg\n",
      "./data/training/Meat/342.jpg\n",
      "./data/training/Meat/343.jpg\n",
      "./data/training/Meat/344.jpg\n",
      "./data/training/Meat/345.jpg\n",
      "./data/training/Meat/346.jpg\n",
      "./data/training/Meat/347.jpg\n",
      "./data/training/Meat/348.jpg\n",
      "./data/training/Meat/349.jpg\n",
      "./data/training/Meat/35.jpg\n",
      "./data/training/Meat/350.jpg\n",
      "./data/training/Meat/351.jpg\n",
      "./data/training/Meat/352.jpg\n",
      "./data/training/Meat/353.jpg\n",
      "./data/training/Meat/354.jpg\n",
      "./data/training/Meat/355.jpg\n",
      "./data/training/Meat/356.jpg\n",
      "./data/training/Meat/357.jpg\n",
      "./data/training/Meat/358.jpg\n",
      "./data/training/Meat/359.jpg\n",
      "./data/training/Meat/36.jpg\n",
      "./data/training/Meat/360.jpg\n",
      "./data/training/Meat/361.jpg\n",
      "./data/training/Meat/362.jpg\n",
      "./data/training/Meat/363.jpg\n",
      "./data/training/Meat/364.jpg\n",
      "./data/training/Meat/365.jpg\n",
      "./data/training/Meat/366.jpg\n",
      "./data/training/Meat/367.jpg\n",
      "./data/training/Meat/368.jpg\n",
      "./data/training/Meat/369.jpg\n",
      "./data/training/Meat/37.jpg\n",
      "./data/training/Meat/370.jpg\n",
      "./data/training/Meat/371.jpg\n",
      "./data/training/Meat/372.jpg\n",
      "./data/training/Meat/373.jpg\n",
      "./data/training/Meat/374.jpg\n",
      "./data/training/Meat/375.jpg\n",
      "./data/training/Meat/376.jpg\n",
      "./data/training/Meat/377.jpg\n",
      "./data/training/Meat/378.jpg\n",
      "./data/training/Meat/379.jpg\n",
      "./data/training/Meat/38.jpg\n",
      "./data/training/Meat/380.jpg\n",
      "./data/training/Meat/381.jpg\n",
      "./data/training/Meat/382.jpg\n",
      "./data/training/Meat/383.jpg\n",
      "./data/training/Meat/384.jpg\n",
      "./data/training/Meat/385.jpg\n",
      "./data/training/Meat/386.jpg\n",
      "./data/training/Meat/387.jpg\n",
      "./data/training/Meat/388.jpg\n",
      "./data/training/Meat/389.jpg\n",
      "./data/training/Meat/39.jpg\n",
      "./data/training/Meat/390.jpg\n",
      "./data/training/Meat/391.jpg\n",
      "./data/training/Meat/392.jpg\n",
      "./data/training/Meat/393.jpg\n",
      "./data/training/Meat/394.jpg\n",
      "./data/training/Meat/395.jpg\n",
      "./data/training/Meat/396.jpg\n",
      "./data/training/Meat/397.jpg\n",
      "./data/training/Meat/398.jpg\n",
      "./data/training/Meat/399.jpg\n",
      "./data/training/Meat/4.jpg\n",
      "./data/training/Meat/40.jpg\n",
      "./data/training/Meat/400.jpg\n",
      "./data/training/Meat/401.jpg\n",
      "./data/training/Meat/402.jpg\n",
      "./data/training/Meat/403.jpg\n",
      "./data/training/Meat/404.jpg\n",
      "./data/training/Meat/405.jpg\n",
      "./data/training/Meat/406.jpg\n",
      "./data/training/Meat/407.jpg\n",
      "./data/training/Meat/408.jpg\n",
      "./data/training/Meat/409.jpg\n",
      "./data/training/Meat/41.jpg\n",
      "./data/training/Meat/410.jpg\n",
      "./data/training/Meat/411.jpg\n",
      "./data/training/Meat/412.jpg\n",
      "./data/training/Meat/413.jpg\n",
      "./data/training/Meat/414.jpg\n",
      "./data/training/Meat/415.jpg\n",
      "./data/training/Meat/416.jpg\n",
      "./data/training/Meat/417.jpg\n",
      "./data/training/Meat/418.jpg\n",
      "./data/training/Meat/419.jpg\n",
      "./data/training/Meat/42.jpg\n",
      "./data/training/Meat/420.jpg\n",
      "./data/training/Meat/421.jpg\n",
      "./data/training/Meat/422.jpg\n",
      "./data/training/Meat/423.jpg\n",
      "./data/training/Meat/424.jpg\n",
      "./data/training/Meat/425.jpg\n",
      "./data/training/Meat/426.jpg\n",
      "./data/training/Meat/427.jpg\n",
      "./data/training/Meat/428.jpg\n",
      "./data/training/Meat/429.jpg\n",
      "./data/training/Meat/43.jpg\n",
      "./data/training/Meat/430.jpg\n",
      "./data/training/Meat/431.jpg\n",
      "./data/training/Meat/432.jpg\n",
      "./data/training/Meat/433.jpg\n",
      "./data/training/Meat/434.jpg\n",
      "./data/training/Meat/435.jpg\n",
      "./data/training/Meat/436.jpg\n",
      "./data/training/Meat/437.jpg\n",
      "./data/training/Meat/438.jpg\n",
      "./data/training/Meat/439.jpg\n",
      "./data/training/Meat/44.jpg\n",
      "./data/training/Meat/440.jpg\n",
      "./data/training/Meat/441.jpg\n",
      "./data/training/Meat/442.jpg\n",
      "./data/training/Meat/443.jpg\n",
      "./data/training/Meat/444.jpg\n",
      "./data/training/Meat/445.jpg\n",
      "./data/training/Meat/446.jpg\n",
      "./data/training/Meat/447.jpg\n",
      "./data/training/Meat/448.jpg\n",
      "./data/training/Meat/449.jpg\n",
      "./data/training/Meat/45.jpg\n",
      "./data/training/Meat/450.jpg\n",
      "./data/training/Meat/451.jpg\n",
      "./data/training/Meat/452.jpg\n",
      "./data/training/Meat/453.jpg\n",
      "./data/training/Meat/454.jpg\n",
      "./data/training/Meat/455.jpg\n",
      "./data/training/Meat/456.jpg\n",
      "./data/training/Meat/457.jpg\n",
      "./data/training/Meat/458.jpg\n",
      "./data/training/Meat/459.jpg\n",
      "./data/training/Meat/46.jpg\n",
      "./data/training/Meat/460.jpg\n",
      "./data/training/Meat/461.jpg\n",
      "./data/training/Meat/462.jpg\n",
      "./data/training/Meat/463.jpg\n",
      "./data/training/Meat/464.jpg\n",
      "./data/training/Meat/465.jpg\n",
      "./data/training/Meat/466.jpg\n",
      "./data/training/Meat/467.jpg\n",
      "./data/training/Meat/468.jpg\n",
      "./data/training/Meat/469.jpg\n",
      "./data/training/Meat/47.jpg\n",
      "./data/training/Meat/470.jpg\n",
      "./data/training/Meat/471.jpg\n",
      "./data/training/Meat/472.jpg\n",
      "./data/training/Meat/473.jpg\n",
      "./data/training/Meat/474.jpg\n",
      "./data/training/Meat/475.jpg\n",
      "./data/training/Meat/476.jpg\n",
      "./data/training/Meat/477.jpg\n",
      "./data/training/Meat/478.jpg\n",
      "./data/training/Meat/479.jpg\n",
      "./data/training/Meat/48.jpg\n",
      "./data/training/Meat/480.jpg\n",
      "./data/training/Meat/481.jpg\n",
      "./data/training/Meat/482.jpg\n",
      "./data/training/Meat/483.jpg\n",
      "./data/training/Meat/484.jpg\n",
      "./data/training/Meat/485.jpg\n",
      "./data/training/Meat/486.jpg\n",
      "./data/training/Meat/487.jpg\n",
      "./data/training/Meat/488.jpg\n",
      "./data/training/Meat/489.jpg\n",
      "./data/training/Meat/49.jpg\n",
      "./data/training/Meat/490.jpg\n",
      "./data/training/Meat/491.jpg\n",
      "./data/training/Meat/492.jpg\n",
      "./data/training/Meat/493.jpg\n",
      "./data/training/Meat/494.jpg\n",
      "./data/training/Meat/495.jpg\n",
      "./data/training/Meat/496.jpg\n",
      "./data/training/Meat/497.jpg\n",
      "./data/training/Meat/498.jpg\n",
      "./data/training/Meat/499.jpg\n",
      "./data/training/Meat/5.jpg\n",
      "./data/training/Meat/50.jpg\n",
      "./data/training/Meat/51.jpg\n",
      "./data/training/Meat/52.jpg\n",
      "./data/training/Meat/53.jpg\n",
      "./data/training/Meat/54.jpg\n",
      "./data/training/Meat/55.jpg\n",
      "./data/training/Meat/56.jpg\n",
      "./data/training/Meat/57.jpg\n",
      "./data/training/Meat/58.jpg\n",
      "./data/training/Meat/59.jpg\n",
      "./data/training/Meat/6.jpg\n",
      "./data/training/Meat/60.jpg\n",
      "./data/training/Meat/61.jpg\n",
      "./data/training/Meat/62.jpg\n",
      "./data/training/Meat/63.jpg\n",
      "./data/training/Meat/64.jpg\n",
      "./data/training/Meat/65.jpg\n",
      "./data/training/Meat/66.jpg\n",
      "./data/training/Meat/67.jpg\n",
      "./data/training/Meat/68.jpg\n",
      "./data/training/Meat/69.jpg\n",
      "./data/training/Meat/7.jpg\n",
      "./data/training/Meat/70.jpg\n",
      "./data/training/Meat/71.jpg\n",
      "./data/training/Meat/72.jpg\n",
      "./data/training/Meat/73.jpg\n",
      "./data/training/Meat/74.jpg\n",
      "./data/training/Meat/75.jpg\n",
      "./data/training/Meat/76.jpg\n",
      "./data/training/Meat/77.jpg\n",
      "./data/training/Meat/78.jpg\n",
      "./data/training/Meat/79.jpg\n",
      "./data/training/Meat/8.jpg\n",
      "./data/training/Meat/80.jpg\n",
      "./data/training/Meat/81.jpg\n",
      "./data/training/Meat/82.jpg\n",
      "./data/training/Meat/83.jpg\n",
      "./data/training/Meat/84.jpg\n",
      "./data/training/Meat/85.jpg\n",
      "./data/training/Meat/86.jpg\n",
      "./data/training/Meat/87.jpg\n",
      "./data/training/Meat/88.jpg\n",
      "./data/training/Meat/89.jpg\n",
      "./data/training/Meat/9.jpg\n",
      "./data/training/Meat/90.jpg\n",
      "./data/training/Meat/91.jpg\n",
      "./data/training/Meat/92.jpg\n",
      "./data/training/Meat/93.jpg\n",
      "./data/training/Meat/94.jpg\n",
      "./data/training/Meat/95.jpg\n",
      "./data/training/Meat/96.jpg\n",
      "./data/training/Meat/97.jpg\n",
      "./data/training/Meat/98.jpg\n",
      "./data/training/Meat/99.jpg\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# import os\n",
    "for dirname, _, filenames in os.walk('./data/training'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_list = []\n",
    "labels = []\n",
    "countA = 0;\n",
    "countB = 0;\n",
    "for dirname, _, filenames in os.walk('./data/training'):\n",
    "    for filename in filenames:\n",
    "        if dirname == './data/training/Fried Food':\n",
    "            if countA >= 75:\n",
    "                continue\n",
    "            X_list.append(\n",
    "                cv.cvtColor(\n",
    "                    cv.imread(os.path.join(dirname, filename))\n",
    "                    ,cv.COLOR_BGR2RGB)\n",
    "            )\n",
    "            labels.append('FriedFood')\n",
    "            countA = countA + 1\n",
    "        elif dirname == './data/training/Meat':\n",
    "            if countB >= 75:\n",
    "                continue\n",
    "            X_list.append(cv.cvtColor(\n",
    "                    cv.imread(os.path.join(dirname, filename))\n",
    "                    ,cv.COLOR_BGR2RGB)\n",
    "            )\n",
    "            labels.append('Meat')\n",
    "            countB = countB+1\n",
    "        if countA >= 75 and countB >= 75:\n",
    "            break\n",
    "\n",
    "\n",
    "X = np.asarray(X_list)\n",
    "\n",
    "# print(image)\n",
    "# print(image.shape)\n",
    "# plt.imshow(image_cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanMoment(channel):\n",
    "    sumValue = 0\n",
    "    countValue = 0\n",
    "    for i in range(len(channel)):\n",
    "        for j in range(len(channel[i])):\n",
    "            #if(channel[i][j] < 99):\n",
    "            if(channel[i][j] < 200):\n",
    "                sumValue += channel[i][j]\n",
    "                countValue += 1\n",
    "    if(countValue == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return sumValue/countValue\n",
    "\n",
    "def varianceMoment(channel, meanChannel):\n",
    "    sumValue = 0\n",
    "    countValue = 0\n",
    "    for i in range(len(channel)):\n",
    "        for j in range(len(channel[i])):\n",
    "            #if(channel[i][j] < 99):\n",
    "            if(channel[i][j] < 200):\n",
    "                sumValue += np.power(channel[i][j] - meanChannel,2)\n",
    "                countValue += 1\n",
    "    if(countValue == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sqrt(sumValue/countValue)\n",
    "\n",
    "def skewnessMoment(channel, meanChannel):\n",
    "    sumValue = np.int64(0)\n",
    "    countValue = 0\n",
    "    for i in range(len(channel)):\n",
    "        for j in range(len(channel[i])):\n",
    "            #if(channel[i][j] < 99):\n",
    "            if(channel[i][j] < 200):\n",
    "                sumValue += np.power(channel[i][j] - meanChannel,3)\n",
    "                countValue += 1\n",
    "    if(countValue == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.cbrt(sumValue/countValue)\n",
    "    \n",
    "def getColorMoment(channel):\n",
    "    meanChannel = meanMoment(channel)\n",
    "    varChannel = varianceMoment(channel, meanChannel)\n",
    "    skewChannel = skewnessMoment(channel, meanChannel)\n",
    "    #return meanChannel, varChannel, skewChannel\n",
    "    return meanChannel, varChannel, skewChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [meanR, varR, skewR, meanG, varG, skewG, meanB, varB, skewB]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "meanR_list = []\n",
    "varR_list = []\n",
    "skewR_list = []\n",
    "meanG_list = []\n",
    "varG_list = []\n",
    "skewG_list = []\n",
    "meanB_list = []\n",
    "varB_list = []\n",
    "skewB_list = []\n",
    "aRatio_list = []\n",
    "roundness_list = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    h = X[i].shape[0]\n",
    "    w = X[i].shape[1]\n",
    "    ymin, ymax, xmin, xmax = h//3, h*2//3, w//3, w*2//3\n",
    "    crop = X[i][ymin:ymax, xmin:xmax]\n",
    "    resized = cv.resize(crop, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    meanR, varR, skewR = getColorMoment(crop[:,:,0]/255)\n",
    "    meanG, varG, skewG = getColorMoment(crop[:,:,1]/255)\n",
    "    meanB, varB, skewB = getColorMoment(crop[:,:,2]/255)\n",
    "    \n",
    "    meanR_list.append(meanR)\n",
    "    varR_list.append(varR)\n",
    "    skewR_list.append(skewR)\n",
    "    meanG_list.append(meanG)\n",
    "    varG_list.append(varG)\n",
    "    skewG_list.append(skewG)\n",
    "    meanB_list.append(meanB)\n",
    "    varB_list.append(varB)\n",
    "    skewB_list.append(skewB)\n",
    "\n",
    "df['meanR'] = meanR_list\n",
    "df['varR'] = varR_list\n",
    "df['skewR'] = skewR_list\n",
    "df['meanG'] = meanG_list\n",
    "df['varG'] = varG_list\n",
    "df['skewG'] = skewG_list\n",
    "df['meanB'] = meanB_list\n",
    "df['varB'] = varB_list\n",
    "df['skewB'] = skewB_list\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import greycomatrix, greycoprops\n",
    "gray_list = []\n",
    "for i in range(len(X)):\n",
    "    gray = cv.cvtColor(X[i], cv.COLOR_RGB2GRAY)\n",
    "    \n",
    "    h = gray.shape[0]\n",
    "    w = gray.shape[1]\n",
    "    ymin, ymax, xmin, xmax = h//3, h*2//3, w//3, w*2//3\n",
    "    crop = gray[ymin:ymax, xmin:xmax]\n",
    "    \n",
    "    resized = cv.resize(crop, (0,0), fx=0.5, fy=0.5)\n",
    "    gray_list.append(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_glcm_all_agls(img, label, props, dists=[5], agls=[0, np.pi/4, np.pi/2, 3*np.pi/4], lvl=256, sym=True, norm=True):\n",
    "    \n",
    "    glcm = greycomatrix(img, \n",
    "                        distances=dists, \n",
    "                        angles=agls, \n",
    "                        levels=lvl,\n",
    "                        symmetric=sym, \n",
    "                        normed=norm)\n",
    "    feature = []\n",
    "    glcm_props = [propery for name in props for propery in greycoprops(glcm, name)[0]]\n",
    "    for item in glcm_props:\n",
    "            feature.append(item)\n",
    "    feature.append(label) \n",
    "    \n",
    "    return feature\n",
    "\n",
    "\n",
    "# ----------------- call calc_glcm_all_agls() for all properties ----------------------------------\n",
    "properties = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']\n",
    "\n",
    "glcm_all_agls = []\n",
    "for img, label in zip(gray_list, labels): \n",
    "    glcm_all_agls.append(\n",
    "            calc_glcm_all_agls(img, \n",
    "                                label, \n",
    "                                props=properties)\n",
    "                            )\n",
    " \n",
    "columns = []\n",
    "angles = ['0', '45', '90','135']\n",
    "for name in properties :\n",
    "    for ang in angles:\n",
    "        columns.append(name + \"_\" + ang)\n",
    "        \n",
    "columns.append(\"label\")\n",
    "\n",
    "glcm_df = pd.DataFrame(glcm_all_agls, \n",
    "                      columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "new_df = pd.concat([df,glcm_df], axis=1)\n",
    "X = new_df.iloc[:, :-1].values\n",
    "y = new_df.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4f30429c224a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to C:\\Users\\Acer/.cache\\torch\\hub\\v0.6.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\Acer/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off training for their parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms as T\n",
    "composed = T.Compose([T.Resize(256),\n",
    "                      T.RandomCrop(224),\n",
    "                      T.ToTensor()])\n",
    "image_data = datasets.ImageFolder(root='./data/training/',transform = composed)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(image_data, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "Caught ModuleAttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\datasets\\folder.py\", line 153, in __getitem__\n    sample = self.transform(sample)\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\transforms\\transforms.py\", line 67, in __call__\n    img = t(img)\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 730, in _call_impl\n    self._forward_hooks.values()):\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 778, in __getattr__\n    raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\ntorch.nn.modules.module.ModuleAttributeError: 'Resize' object has no attribute '_forward_hooks'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-200a10f60b69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# have message field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: Caught ModuleAttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\datasets\\folder.py\", line 153, in __getitem__\n    sample = self.transform(sample)\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\transforms\\transforms.py\", line 67, in __call__\n    img = t(img)\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 730, in _call_impl\n    self._forward_hooks.values()):\n  File \"C:\\Users\\Acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 778, in __getattr__\n    raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\ntorch.nn.modules.module.ModuleAttributeError: 'Resize' object has no attribute '_forward_hooks'\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
